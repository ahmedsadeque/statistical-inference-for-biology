---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 18-lm-intro.md in _episodes_rmd/
title: "Introduction to Linear Models"
teaching: 0
exercises: 0
questions:
- "?"
- "?"
- "?"
objectives:
- ""
- ""
- ""
- ""
- ""
- ""
- ""
keypoints:
- "."
- "."
- "."
- "."
source: Rmd
---



# Linear Models

Many of the models we use in data analysis can be presented using matrix algebra. We refer to these types of models as _linear models_. "Linear" here does not refer to lines, but rather to linear combinations. The representations we describe are convenient because we can write models more succinctly and we have the matrix algebra mathematical machinery to facilitate computation. In this chapter, we will describe in some detail how we use matrix algebra to represent and fit.

In this book, we focus on linear models that represent dichotomous groups: treatment versus control, for example. The effect of diet on mice weights is an example of this type of linear model. Here we describe slightly more complicated models, but continue to focus on dichotomous variables. 

As we learn about linear models, we need to remember that we are still working with random variables. This means that the estimates we obtain using linear models are also random variables. Although the mathematics is more complex, the concepts we learned in previous chapters apply here. We begin with some exercises to review the concept of random variables in the context of linear models.


ExercisesThe standard error of an estimate is the standard deviation of the sampling distribution of anestimate. In previous chapters, we saw that our estimate of the mean of a population changeddepending on the sample that we took from the population. If we repeatedly sampled from thepopulation and each time estimated the mean, the collection of mean estimates would form thesampling distribution of the estimate. When we took the standard deviation of those estimates,that was the standard error of our mean estimate.In the case of a linear model written as:Yi=0+1Xi+"i; i= 1; : : : ; n"is considered random. Every time we re-run the experiment, we will see different"dichotomous.This implies that in different application"represents different things: measurement error orvariability between individuals for example.If we were to re-run the experiment many times and estimate linear model terms^each time, thedistribution of these^is called the sampling distribution of the estimates. If we take the standarddeviation of all of these estimates from repetitions of the experiment, this is called the standarderror of the estimate. While we are not necesarily sampling individuals, you can think about therepetition of the experiment as “sampling” new errors in our observation ofY.

We have shown how to find the least squares estimates with matrix algebra. These estimatesare random variables as they are linear combinations of the data. For these estimates to beuseful, we also need to compute the standard errors. Here we review standard errors inthe context of linear models. To see this, we can run a Monte Carlo simulation to imitatethe collection of falling object data. Specifically, we will generate the data repeatedly andcompute the estimate for the quadratic term each time.g=9.8h0=56.67v0=0n=25tt=seq(0,3.4,len=n)y=h0+v0*tt-0.5*g*tt^2+rnorm(n,sd=1)Now we act as if we didn’t know h0, v0 and -0.5*g and use regression to estimate these. Wecan rewrite the model asy=0+1t+2t2+"and obtain the LSE we have used in thisclass. Note that g = -22.To obtain the LSE in R we could write:X=cbind(1,tt,tt^2)A=solve(crossprod(X))%*%t(X)Given how we have definedA, which of the following is the LSE of g, the acceleration dueto gravity? Hint: try the code in R.•A)9.8•B)A %*% y•C)-2 * (A %*% y) [3]•D)A[3,3]2.In the lines of code above, the functionrnormintroduced randomness. This means that eachtime the lines of code above are repeated, the estimate of g will be different.Use the code above in conjunction with the functionreplicateto generate 100,000 MonteCarlo simulated datasets. For each dataset, compute an estimate ofg. (Remember to multiplyby -2.)What is the standard error of this estimate?3.In the father and son height examples, we have randomness because we have a randomsample of father and son pairs. For the sake of illustration, let’s assume that this is the entirepopulation:library(UsingR)x=father.son$fheighty=father.son$sheightn=length(y)

Now let’s run a Monte Carlo simulation in which we take a sample of size 50 over and overagain. Here is how we obtain one sample:N=50index=sample(n,N)sampledat=father.son[index,]x=sampledat$fheighty=sampledat$sheightbetahat=lm(y~x)$coefUse the function replicate to take 10,000 samples.What is the standard error of the slope estimate? That is, calculate the standard deviationof the estimate from the observed values obtained from many random samples.4.Later in this chapter we will introduce a new concept: covariance. The covariance of twolists of numbersX=x1; :::; xnandY=y1; :::; ynis:n<-100Y<-rnorm(n)X<-rnorm(n)mean( (Y-mean(Y))*(X-mean(X) ) )Which of the following is closest to the covariance between father heights and son heights?•A) 0•B) -4•C) 4•D) 0.5

